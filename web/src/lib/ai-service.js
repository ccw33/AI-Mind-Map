// AIæœåŠ¡æ¥å£ - ç»Ÿä¸€çš„AIè°ƒç”¨æ¥å£ï¼Œæ”¯æŒå¤šç§AIæä¾›å•†
// ç§»æ¤è‡ªai-mind-mapé¡¹ç›®ï¼Œé€‚é…Vue.jsç¯å¢ƒ

import { getCurrentAIConfig, validateAIConfig, debugLog, getMindMapAIConfig, AI_PROVIDERS } from './ai-config.js'

// AIæœåŠ¡ç±»
export class AIService {
  constructor() {
    this.config = getCurrentAIConfig()
    this.conversationHistory = []
    this.mindMapConfig = getMindMapAIConfig()

    if (!validateAIConfig(this.config)) {
      console.warn('AIé…ç½®ä¸å®Œæ•´ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ')
    }
  }

  // å‘é€èŠå¤©æ¶ˆæ¯
  async sendMessage(message, context = null) {
    try {
      debugLog('å‘é€AIæ¶ˆæ¯', { message, context, config: this.config })

      // æ„å»ºæ¶ˆæ¯å†å²
      const messages = this.buildMessages(message, context)

      // æ ¹æ®æä¾›å•†è°ƒç”¨ç›¸åº”çš„API
      const response = await this.callAI(messages)

      // æ›´æ–°å¯¹è¯å†å²
      if (this.mindMapConfig.enableContextMemory) {
        this.updateConversationHistory(message, response.content)
      }

      debugLog('AIå“åº”', response)
      return response

    } catch (error) {
      console.error('AIæœåŠ¡è°ƒç”¨å¤±è´¥:', error)
      throw new Error('AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•')
    }
  }

  // æ„å»ºæ¶ˆæ¯åˆ—è¡¨
  buildMessages(userMessage, context) {
    const messages = []

    // ç³»ç»Ÿæç¤ºè¯
    let systemPrompt = 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ€ç»´å¯¼å›¾åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·æ‰©å±•å’Œå®Œå–„æ€ç»´å¯¼å›¾å†…å®¹ã€‚'

    if (context && context.selectedNode) {
      const { text, hierarchy, hierarchyWithNotes } = context.selectedNode
      systemPrompt += `\n\nå½“å‰ç”¨æˆ·é€‰ä¸­çš„èŠ‚ç‚¹æ˜¯ï¼š"${text}"ï¼Œä½äºæ€ç»´å¯¼å›¾çš„å±‚çº§ï¼š${hierarchy.join(' > ')}ã€‚`

      // æ·»åŠ èŠ‚ç‚¹é“¾è·¯çš„è¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…æ‹¬å¤‡æ³¨ï¼‰
      if (hierarchyWithNotes && hierarchyWithNotes.length > 0) {
        systemPrompt += `\n\nèŠ‚ç‚¹é“¾è·¯è¯¦ç»†ä¿¡æ¯ï¼š`
        hierarchyWithNotes.forEach((nodeInfo, index) => {
          systemPrompt += `\n${index + 1}. èŠ‚ç‚¹ï¼š"${nodeInfo.text}"`
          if (nodeInfo.note && nodeInfo.note.trim()) {
            systemPrompt += `\n   å¤‡æ³¨ï¼š${nodeInfo.note.trim()}`
          }
        })
      }

      systemPrompt += `\n\nè¯·åŸºäºè¿™ä¸ªèŠ‚ç‚¹çš„ä¸Šä¸‹æ–‡å’Œé“¾è·¯ä¿¡æ¯æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚`
    }

    messages.push({
      role: 'system',
      content: systemPrompt
    })

    // æ·»åŠ å¯¹è¯å†å²ï¼ˆå¦‚æœå¯ç”¨äº†ä¸Šä¸‹æ–‡è®°å¿†ï¼‰
    if (this.mindMapConfig.enableContextMemory && this.conversationHistory.length > 0) {
      const recentHistory = this.conversationHistory.slice(-this.mindMapConfig.contextMemoryRounds * 2)
      messages.push(...recentHistory)
    }

    // æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
    messages.push({
      role: 'user',
      content: userMessage
    })

    return messages
  }

  // è°ƒç”¨AI API
  async callAI(messages) {
    const { provider } = this.config

    switch (provider) {
      case AI_PROVIDERS.OPENAI:
      case AI_PROVIDERS.DEEPSEEK:
        return await this.callOpenAICompatibleAPI(messages)
      case AI_PROVIDERS.ANTHROPIC:
        return await this.callAnthropicAPI(messages)
      case AI_PROVIDERS.OLLAMA:
        return await this.callOllamaAPI(messages)
      default:
        throw new Error(`ä¸æ”¯æŒçš„AIæä¾›å•†: ${provider}`)
    }
  }

  // è°ƒç”¨OpenAIå…¼å®¹çš„APIï¼ˆåŒ…æ‹¬OpenAIã€DeepSeekç­‰ï¼‰
  async callOpenAICompatibleAPI(messages) {
    const { apiKey, baseURL, model } = this.config

    // æ‰“å°è¯·æ±‚çš„promptåˆ°æ§åˆ¶å°
    console.log('=== LLM API è¯·æ±‚ (Vueç‰ˆæœ¬) ===');
    console.log('ğŸ”§ é…ç½®ä¿¡æ¯:', { provider: this.config.provider, model, baseURL: baseURL.replace(/\/+$/, '') });
    console.log('ğŸ“ å®Œæ•´è¯·æ±‚æ¶ˆæ¯:', JSON.stringify(messages, null, 2));
    console.log('ğŸ¤– ç³»ç»Ÿæç¤ºè¯:', messages.find(m => m.role === 'system')?.content || 'æ— ');
    console.log('ğŸ’¬ ç”¨æˆ·æ¶ˆæ¯:', messages.find(m => m.role === 'user')?.content || 'æ— ');
    console.log('==================');

    const requestBody = {
      model,
      messages,
      max_tokens: this.mindMapConfig.maxResponseLength,
      temperature: 0.7,
      stream: false
    }

    const response = await fetch(`${baseURL}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      console.error('âŒ APIè¯·æ±‚å¤±è´¥:', response.status, response.statusText);
      throw new Error(`APIè¯·æ±‚å¤±è´¥: ${response.status} ${response.statusText}`)
    }

    const data = await response.json()

    if (!data.choices || !data.choices[0]) {
      throw new Error('APIè¿”å›æ•°æ®æ ¼å¼é”™è¯¯')
    }

    const content = data.choices[0].message.content
    const suggestions = this.extractSuggestions(content)

    // æ‰“å°åŸå§‹å“åº”åˆ°æ§åˆ¶å°
    console.log('=== LLM API å“åº” (Vueç‰ˆæœ¬) ===');
    console.log('ğŸ“Š å®Œæ•´å“åº”æ•°æ®:', JSON.stringify(data, null, 2));
    console.log('ğŸ’­ åŸå§‹å›ç­”å†…å®¹:', content);
    if (data.usage) {
      console.log('ğŸ“ˆ Tokenä½¿ç”¨æƒ…å†µ:', data.usage);
    }
    console.log('ğŸ’¡ æå–çš„å»ºè®®:', suggestions);
    console.log('==================');

    return {
      content,
      suggestions,
      usage: data.usage
    }
  }

  // è°ƒç”¨Anthropic API
  async callAnthropicAPI(messages) {
    // å®ç°Anthropic APIè°ƒç”¨é€»è¾‘
    throw new Error('Anthropic APIæš‚æœªå®ç°')
  }

  // è°ƒç”¨Ollama API
  async callOllamaAPI(messages) {
    const { baseURL, model } = this.config

    // æ‰“å°è¯·æ±‚çš„promptåˆ°æ§åˆ¶å°
    console.log('=== Ollama API è¯·æ±‚ (Vueç‰ˆæœ¬) ===');
    console.log('ğŸ”§ é…ç½®ä¿¡æ¯:', { provider: this.config.provider, model, baseURL: baseURL.replace(/\/+$/, '') });
    console.log('ğŸ“ å®Œæ•´è¯·æ±‚æ¶ˆæ¯:', JSON.stringify(messages, null, 2));
    console.log('ğŸ¤– ç³»ç»Ÿæç¤ºè¯:', messages.find(m => m.role === 'system')?.content || 'æ— ');
    console.log('ğŸ’¬ ç”¨æˆ·æ¶ˆæ¯:', messages.find(m => m.role === 'user')?.content || 'æ— ');
    console.log('==================');

    const requestBody = {
      model,
      messages,
      stream: false
    }

    const response = await fetch(`${baseURL}/api/chat`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      console.error('âŒ Ollama APIè¯·æ±‚å¤±è´¥:', response.status, response.statusText);
      throw new Error(`Ollama APIè¯·æ±‚å¤±è´¥: ${response.status} ${response.statusText}`)
    }

    const data = await response.json()
    const content = data.message.content
    const suggestions = this.extractSuggestions(content)

    // æ‰“å°åŸå§‹å“åº”åˆ°æ§åˆ¶å°
    console.log('=== Ollama API å“åº” (Vueç‰ˆæœ¬) ===');
    console.log('ğŸ“Š å®Œæ•´å“åº”æ•°æ®:', JSON.stringify(data, null, 2));
    console.log('ğŸ’­ åŸå§‹å›ç­”å†…å®¹:', content);
    console.log('ğŸ’¡ æå–çš„å»ºè®®:', suggestions);
    console.log('==================');

    return {
      content,
      suggestions
    }
  }

  // ä»AIå›å¤ä¸­æå–å»ºè®®
  extractSuggestions(content) {
    const suggestions = []

    // ç®€å•çš„å»ºè®®æå–é€»è¾‘ï¼Œå¯ä»¥æ ¹æ®éœ€è¦ä¼˜åŒ–
    const lines = content.split('\n')
    lines.forEach(line => {
      const trimmed = line.trim()
      if (trimmed.startsWith('- ') || trimmed.startsWith('â€¢ ')) {
        const text = trimmed.substring(2).trim()
        if (text.length > 0 && text.length < 50) {
          suggestions.push({
            text,
            type: 'child',
            description: 'æ¥è‡ªAIçš„å»ºè®®'
          })
        }
      }
    })

    return suggestions.slice(0, this.mindMapConfig.suggestionCount)
  }

  // æ›´æ–°å¯¹è¯å†å²
  updateConversationHistory(userMessage, aiResponse) {
    this.conversationHistory.push(
      { role: 'user', content: userMessage },
      { role: 'assistant', content: aiResponse }
    )

    // é™åˆ¶å†å²è®°å½•é•¿åº¦
    const maxHistory = this.mindMapConfig.contextMemoryRounds * 2
    if (this.conversationHistory.length > maxHistory) {
      this.conversationHistory = this.conversationHistory.slice(-maxHistory)
    }
  }

  // æ¸…é™¤å¯¹è¯å†å²
  clearHistory() {
    this.conversationHistory = []
  }

  // æ›´æ–°é…ç½®
  updateConfig(newConfig) {
    this.config = { ...this.config, ...newConfig }
    this.mindMapConfig = getMindMapAIConfig()
  }
}

// åˆ›å»ºå…¨å±€AIæœåŠ¡å®ä¾‹
export const aiService = new AIService()

// å¯¼å‡ºä¾¿æ·æ–¹æ³•
export async function sendAIMessage(message, context = null) {
  return await aiService.sendMessage(message, context)
}

export function clearAIHistory() {
  aiService.clearHistory()
}

export function updateAIConfig(config) {
  aiService.updateConfig(config)
}
