// AIæœåŠ¡æ¥å£ - ç»Ÿä¸€çš„AIè°ƒç”¨æ¥å£ï¼Œæ”¯æŒå¤šç§AIæä¾›å•†
// ç§»æ¤è‡ªai-mind-mapé¡¹ç›®ï¼Œé€‚é…Vue.jsç¯å¢ƒ

import { getCurrentAIConfig, validateAIConfig, debugLog, getMindMapAIConfig, AI_PROVIDERS, buildSystemPrompt } from './ai-config.js'

// AIæœåŠ¡ç±»
export class AIService {
  constructor() {
    this.config = getCurrentAIConfig()
    this.conversationHistory = []
    this.mindMapConfig = getMindMapAIConfig()

    if (!validateAIConfig(this.config)) {
      console.warn('AIé…ç½®ä¸å®Œæ•´ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ')
    }
  }

  // å‘é€èŠå¤©æ¶ˆæ¯
  async sendMessage(message, context = null) {
    try {
      debugLog('å‘é€AIæ¶ˆæ¯', { message, context, config: this.config })

      // æ„å»ºæ¶ˆæ¯å†å²
      const messages = this.buildMessages(message, context)

      // æ ¹æ®æä¾›å•†è°ƒç”¨ç›¸åº”çš„API
      const response = await this.callAI(messages)

      // æ›´æ–°å¯¹è¯å†å²
      if (this.mindMapConfig.enableContextMemory) {
        this.updateConversationHistory(message, response.content)
      }

      debugLog('AIå“åº”', response)
      return response

    } catch (error) {
      console.error('AIæœåŠ¡è°ƒç”¨å¤±è´¥:', error)
      throw new Error('AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•')
    }
  }

  // æ„å»ºæ¶ˆæ¯åˆ—è¡¨
  buildMessages(userMessage, context) {
    const messages = []

    // ä½¿ç”¨æ–°çš„ç³»ç»Ÿæç¤ºè¯æ„å»ºé€»è¾‘
    let systemPrompt = buildSystemPrompt()

    if (context && context.selectedNode) {
      const { text, hierarchy, hierarchyWithNotes } = context.selectedNode
      systemPrompt += `\n\nå½“å‰ç”¨æˆ·é€‰ä¸­çš„èŠ‚ç‚¹æ˜¯ï¼š"${text}"ï¼Œä½äºæ€ç»´å¯¼å›¾çš„å±‚çº§ï¼š${hierarchy.join(' > ')}ã€‚`

      // æ·»åŠ èŠ‚ç‚¹é“¾è·¯çš„è¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…æ‹¬å¤‡æ³¨ï¼‰
      if (hierarchyWithNotes && hierarchyWithNotes.length > 0) {
        systemPrompt += `\n\nèŠ‚ç‚¹é“¾è·¯è¯¦ç»†ä¿¡æ¯ï¼š`
        hierarchyWithNotes.forEach((nodeInfo, index) => {
          systemPrompt += `\n${index + 1}. èŠ‚ç‚¹ï¼š"${nodeInfo.text}"`
          if (nodeInfo.note && nodeInfo.note.trim()) {
            systemPrompt += `\n   å¤‡æ³¨ï¼š${nodeInfo.note.trim()}`
          }
        })
      }

      systemPrompt += `\n\nè¯·åŸºäºè¿™ä¸ªèŠ‚ç‚¹çš„ä¸Šä¸‹æ–‡å’Œé“¾è·¯ä¿¡æ¯æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚`
    }

    messages.push({
      role: 'system',
      content: systemPrompt
    })

    // æ·»åŠ å¯¹è¯å†å²ï¼ˆå¦‚æœå¯ç”¨äº†ä¸Šä¸‹æ–‡è®°å¿†ï¼‰
    if (this.mindMapConfig.enableContextMemory && this.conversationHistory.length > 0) {
      const recentHistory = this.conversationHistory.slice(-this.mindMapConfig.contextMemoryRounds * 2)
      messages.push(...recentHistory)
    }

    // æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
    messages.push({
      role: 'user',
      content: userMessage
    })

    return messages
  }

  // è°ƒç”¨AI API
  async callAI(messages) {
    const { provider } = this.config

    switch (provider) {
      case AI_PROVIDERS.OPENAI:
      case AI_PROVIDERS.DEEPSEEK:
        return await this.callOpenAICompatibleAPI(messages)
      case AI_PROVIDERS.ANTHROPIC:
        return await this.callAnthropicAPI(messages)
      case AI_PROVIDERS.OLLAMA:
        return await this.callOllamaAPI(messages)
      default:
        throw new Error(`ä¸æ”¯æŒçš„AIæä¾›å•†: ${provider}`)
    }
  }

  // è°ƒç”¨OpenAIå…¼å®¹çš„APIï¼ˆåŒ…æ‹¬OpenAIã€DeepSeekç­‰ï¼‰
  async callOpenAICompatibleAPI(messages) {
    const { apiKey, baseURL, model } = this.config

    // æ‰“å°è¯·æ±‚çš„promptåˆ°æ§åˆ¶å°
    console.log('=== LLM API è¯·æ±‚ (Vueç‰ˆæœ¬) ===');
    console.log('ğŸ”§ é…ç½®ä¿¡æ¯:', { provider: this.config.provider, model, baseURL: baseURL.replace(/\/+$/, '') });
    console.log('ğŸ“ å®Œæ•´è¯·æ±‚æ¶ˆæ¯:', JSON.stringify(messages, null, 2));
    console.log('ğŸ¤– ç³»ç»Ÿæç¤ºè¯:', messages.find(m => m.role === 'system')?.content || 'æ— ');
    console.log('ğŸ’¬ ç”¨æˆ·æ¶ˆæ¯:', messages.find(m => m.role === 'user')?.content || 'æ— ');
    console.log('==================');

    const requestBody = {
      model,
      messages,
      max_tokens: this.mindMapConfig.maxResponseLength,
      temperature: 0.7,
      stream: false
    }

    const response = await fetch(`${baseURL}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      console.error('âŒ APIè¯·æ±‚å¤±è´¥:', response.status, response.statusText);
      throw new Error(`APIè¯·æ±‚å¤±è´¥: ${response.status} ${response.statusText}`)
    }

    const data = await response.json()

    if (!data.choices || !data.choices[0]) {
      throw new Error('APIè¿”å›æ•°æ®æ ¼å¼é”™è¯¯')
    }

    const content = data.choices[0].message.content
    const suggestions = this.extractSuggestions(content)

    // æ£€æµ‹å¹¶å¤„ç†æ¨ç†è¿‡ç¨‹
    const reasoningResult = this.extractReasoningProcess(data, content)

    // æ‰“å°åŸå§‹å“åº”åˆ°æ§åˆ¶å°
    console.log('=== LLM API å“åº” (Vueç‰ˆæœ¬) ===');
    console.log('ğŸ“Š å®Œæ•´å“åº”æ•°æ®:', JSON.stringify(data, null, 2));
    console.log('ğŸ’­ åŸå§‹å›ç­”å†…å®¹:', content);

    // å¦‚æœæ˜¯æ¨ç†æ¨¡å‹ï¼Œå•ç‹¬æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹
    if (reasoningResult.isReasoningModel) {
      console.log('ğŸ§  æ¨ç†æ¨¡å‹æ£€æµ‹: æ˜¯');
      if (reasoningResult.reasoning) {
        console.log('ğŸ¤” æ¨ç†è¿‡ç¨‹:');
        console.log('%c' + reasoningResult.reasoning, 'color: #888; font-style: italic;');
      }
      if (reasoningResult.finalAnswer) {
        console.log('âœ… æœ€ç»ˆå›ç­”:', reasoningResult.finalAnswer);
      }
    } else {
      console.log('ğŸ§  æ¨ç†æ¨¡å‹æ£€æµ‹: å¦');
    }

    if (data.usage) {
      console.log('ğŸ“ˆ Tokenä½¿ç”¨æƒ…å†µ:', data.usage);
    }
    console.log('ğŸ’¡ æå–çš„å»ºè®®:', suggestions);
    console.log('==================');

    return {
      content,
      suggestions,
      usage: data.usage
    }
  }

  // è°ƒç”¨Anthropic API
  async callAnthropicAPI(messages) {
    // å®ç°Anthropic APIè°ƒç”¨é€»è¾‘
    throw new Error('Anthropic APIæš‚æœªå®ç°')
  }

  // è°ƒç”¨Ollama API
  async callOllamaAPI(messages) {
    const { baseURL, model } = this.config

    // æ‰“å°è¯·æ±‚çš„promptåˆ°æ§åˆ¶å°
    console.log('=== Ollama API è¯·æ±‚ (Vueç‰ˆæœ¬) ===');
    console.log('ğŸ”§ é…ç½®ä¿¡æ¯:', { provider: this.config.provider, model, baseURL: baseURL.replace(/\/+$/, '') });
    console.log('ğŸ“ å®Œæ•´è¯·æ±‚æ¶ˆæ¯:', JSON.stringify(messages, null, 2));
    console.log('ğŸ¤– ç³»ç»Ÿæç¤ºè¯:', messages.find(m => m.role === 'system')?.content || 'æ— ');
    console.log('ğŸ’¬ ç”¨æˆ·æ¶ˆæ¯:', messages.find(m => m.role === 'user')?.content || 'æ— ');
    console.log('==================');

    const requestBody = {
      model,
      messages,
      stream: false
    }

    const response = await fetch(`${baseURL}/api/chat`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      console.error('âŒ Ollama APIè¯·æ±‚å¤±è´¥:', response.status, response.statusText);
      throw new Error(`Ollama APIè¯·æ±‚å¤±è´¥: ${response.status} ${response.statusText}`)
    }

    const data = await response.json()
    const content = data.message.content
    const suggestions = this.extractSuggestions(content)

    // æ£€æµ‹å¹¶å¤„ç†æ¨ç†è¿‡ç¨‹
    const reasoningResult = this.extractReasoningProcess(data, content)

    // æ‰“å°åŸå§‹å“åº”åˆ°æ§åˆ¶å°
    console.log('=== Ollama API å“åº” (Vueç‰ˆæœ¬) ===');
    console.log('ğŸ“Š å®Œæ•´å“åº”æ•°æ®:', JSON.stringify(data, null, 2));
    console.log('ğŸ’­ åŸå§‹å›ç­”å†…å®¹:', content);

    // å¦‚æœæ˜¯æ¨ç†æ¨¡å‹ï¼Œå•ç‹¬æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹
    if (reasoningResult.isReasoningModel) {
      console.log('ğŸ§  æ¨ç†æ¨¡å‹æ£€æµ‹: æ˜¯');
      if (reasoningResult.reasoning) {
        console.log('ğŸ¤” æ¨ç†è¿‡ç¨‹:');
        console.log('%c' + reasoningResult.reasoning, 'color: #888; font-style: italic;');
      }
      if (reasoningResult.finalAnswer) {
        console.log('âœ… æœ€ç»ˆå›ç­”:', reasoningResult.finalAnswer);
      }
    } else {
      console.log('ğŸ§  æ¨ç†æ¨¡å‹æ£€æµ‹: å¦');
    }

    console.log('ğŸ’¡ æå–çš„å»ºè®®:', suggestions);
    console.log('==================');

    return {
      content,
      suggestions
    }
  }

  // æ£€æµ‹å¹¶æå–æ¨ç†è¿‡ç¨‹
  extractReasoningProcess(data, rawContent) {
    const result = {
      isReasoningModel: false,
      reasoning: null,
      finalAnswer: null
    }

    // æ£€æµ‹æ–¹æ³•1: æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦åŒ…å«æ¨ç†ç›¸å…³å…³é”®è¯
    const modelName = (data.model || '').toLowerCase()
    const reasoningKeywords = ['reasoner', 'reasoning', 'think', 'cot', 'chain-of-thought']
    const isReasoningByModel = reasoningKeywords.some(keyword => modelName.includes(keyword))

    // æ£€æµ‹æ–¹æ³•2: æ£€æŸ¥å“åº”ç»“æ„æ˜¯å¦åŒ…å«æ¨ç†å­—æ®µï¼ˆDeepSeekå®˜æ–¹æ ¼å¼ï¼‰
    const choice = data.choices && data.choices[0]
    const hasDeepSeekReasoningField = choice && choice.message && choice.message.reasoning_content

    // æ£€æµ‹æ–¹æ³•3: æ£€æŸ¥å“åº”ç»“æ„æ˜¯å¦åŒ…å«å…¶ä»–æ¨ç†å­—æ®µï¼ˆå…¼å®¹å…¶ä»–æ ¼å¼ï¼‰
    const hasOtherReasoningField = choice && (choice.reasoning || choice.message?.reasoning)

    // æ£€æµ‹æ–¹æ³•3: æ£€æŸ¥å†…å®¹æ ¼å¼æ˜¯å¦ç¬¦åˆæ¨ç†æ¨¡å¼
    const hasReasoningPattern = rawContent && (
      rawContent.includes('<thinking>') ||
      rawContent.includes('<reasoning>') ||
      rawContent.includes('è®©æˆ‘æ€è€ƒä¸€ä¸‹') ||
      rawContent.includes('æ€è€ƒè¿‡ç¨‹ï¼š') ||
      rawContent.includes('æ¨ç†è¿‡ç¨‹ï¼š') ||
      /^[\s\S]*?(?:æ€è€ƒ|æ¨ç†|åˆ†æ)[\s\S]*?(?:ç»“è®º|ç­”æ¡ˆ|å›ç­”)[\s\S]*$/i.test(rawContent)
    )

    result.isReasoningModel = isReasoningByModel || hasDeepSeekReasoningField || hasOtherReasoningField || hasReasoningPattern

    if (result.isReasoningModel) {
      // æå–æ¨ç†è¿‡ç¨‹
      if (choice && choice.message && choice.message.reasoning_content) {
        // æ–¹æ³•1: DeepSeekå®˜æ–¹æ ¼å¼ - ä»message.reasoning_contentå­—æ®µæå–
        result.reasoning = choice.message.reasoning_content
        result.finalAnswer = rawContent // rawContentå°±æ˜¯contentå­—æ®µçš„å†…å®¹
      } else if (choice && choice.reasoning) {
        // æ–¹æ³•2: ä»APIå“åº”çš„reasoningå­—æ®µæå–ï¼ˆå…¶ä»–æ ¼å¼ï¼‰
        result.reasoning = choice.reasoning
        result.finalAnswer = rawContent
      } else if (choice && choice.message && choice.message.reasoning) {
        // æ–¹æ³•3: ä»message.reasoningå­—æ®µæå–ï¼ˆå…¶ä»–æ ¼å¼ï¼‰
        result.reasoning = choice.message.reasoning
        result.finalAnswer = rawContent
      } else if (rawContent) {
        // æ–¹æ³•3: ä»å†…å®¹ä¸­è§£ææ¨ç†è¿‡ç¨‹
        const reasoningPatterns = [
          // <thinking>æ ‡ç­¾æ ¼å¼
          /<thinking>([\s\S]*?)<\/thinking>/i,
          /<reasoning>([\s\S]*?)<\/reasoning>/i,
          // ä¸­æ–‡æ ¼å¼
          /(?:æ€è€ƒè¿‡ç¨‹ï¼š|æ¨ç†è¿‡ç¨‹ï¼š|è®©æˆ‘æ€è€ƒä¸€ä¸‹[ï¼š:]?)([\s\S]*?)(?:ç»“è®ºï¼š|ç­”æ¡ˆï¼š|å›ç­”ï¼š|æœ€ç»ˆç­”æ¡ˆï¼š)/i,
          // åˆ†æ®µæ ¼å¼
          /^([\s\S]*?)(?:\n\n|^)(?:ç»“è®º|ç­”æ¡ˆ|å›ç­”|æœ€ç»ˆç­”æ¡ˆ)[ï¼š:]?([\s\S]*)$/i
        ]

        for (const pattern of reasoningPatterns) {
          const match = rawContent.match(pattern)
          if (match) {
            if (pattern.source.includes('thinking') || pattern.source.includes('reasoning')) {
              result.reasoning = match[1].trim()
              result.finalAnswer = rawContent.replace(match[0], '').trim()
            } else if (pattern.source.includes('æ€è€ƒè¿‡ç¨‹') || pattern.source.includes('æ¨ç†è¿‡ç¨‹')) {
              result.reasoning = match[1].trim()
              const finalMatch = rawContent.match(/(?:ç»“è®ºï¼š|ç­”æ¡ˆï¼š|å›ç­”ï¼š|æœ€ç»ˆç­”æ¡ˆï¼š)([\s\S]*)$/i)
              result.finalAnswer = finalMatch ? finalMatch[1].trim() : rawContent
            } else {
              result.reasoning = match[1].trim()
              result.finalAnswer = match[2] ? match[2].trim() : rawContent
            }
            break
          }
        }

        // å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ç¡®çš„åˆ†éš”ï¼Œä½†æ£€æµ‹åˆ°æ˜¯æ¨ç†æ¨¡å‹ï¼Œå°è¯•æ™ºèƒ½åˆ†å‰²
        if (!result.reasoning && result.isReasoningModel) {
          const lines = rawContent.split('\n')
          const thinkingLines = []
          const answerLines = []
          let isInAnswer = false

          for (const line of lines) {
            const trimmed = line.trim()
            if (trimmed.match(/^(?:ç»“è®º|ç­”æ¡ˆ|å›ç­”|æœ€ç»ˆç­”æ¡ˆ|æ€»ç»“)[ï¼š:]?/i)) {
              isInAnswer = true
            }

            if (isInAnswer) {
              answerLines.push(line)
            } else {
              thinkingLines.push(line)
            }
          }

          if (thinkingLines.length > 0 && answerLines.length > 0) {
            result.reasoning = thinkingLines.join('\n').trim()
            result.finalAnswer = answerLines.join('\n').trim()
          }
        }
      }
    }

    return result
  }

  // ä»AIå›å¤ä¸­æå–å»ºè®®
  extractSuggestions(content) {
    const suggestions = []

    // ç®€å•çš„å»ºè®®æå–é€»è¾‘ï¼Œå¯ä»¥æ ¹æ®éœ€è¦ä¼˜åŒ–
    const lines = content.split('\n')
    lines.forEach(line => {
      const trimmed = line.trim()
      if (trimmed.startsWith('- ') || trimmed.startsWith('â€¢ ')) {
        const text = trimmed.substring(2).trim()
        if (text.length > 0 && text.length < 50) {
          suggestions.push({
            text,
            type: 'child',
            description: 'æ¥è‡ªAIçš„å»ºè®®'
          })
        }
      }
    })

    return suggestions.slice(0, this.mindMapConfig.suggestionCount)
  }

  // æ›´æ–°å¯¹è¯å†å²
  updateConversationHistory(userMessage, aiResponse) {
    this.conversationHistory.push(
      { role: 'user', content: userMessage },
      { role: 'assistant', content: aiResponse }
    )

    // é™åˆ¶å†å²è®°å½•é•¿åº¦
    const maxHistory = this.mindMapConfig.contextMemoryRounds * 2
    if (this.conversationHistory.length > maxHistory) {
      this.conversationHistory = this.conversationHistory.slice(-maxHistory)
    }
  }

  // æ¸…é™¤å¯¹è¯å†å²
  clearHistory() {
    this.conversationHistory = []
  }

  // æ›´æ–°é…ç½®
  updateConfig(newConfig) {
    this.config = { ...this.config, ...newConfig }
    this.mindMapConfig = getMindMapAIConfig()
  }
}

// åˆ›å»ºå…¨å±€AIæœåŠ¡å®ä¾‹
export const aiService = new AIService()

// å¯¼å‡ºä¾¿æ·æ–¹æ³•
export async function sendAIMessage(message, context = null) {
  return await aiService.sendMessage(message, context)
}

export function clearAIHistory() {
  aiService.clearHistory()
}

export function updateAIConfig(config) {
  aiService.updateConfig(config)
}
